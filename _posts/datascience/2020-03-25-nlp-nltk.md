---
layout: post
title: NLP - nltk
date: 2020-03-25 10:17 -0700
categories: Statistics
tags: [Machine Learning]
---

# Install `NLTK`
In terminal,
```bash
pip install nltk
```

## Use `urllib` module to crawl the web page
```python3
import nltk
import urllib.request
response = urllib.request.urlopen("http://php.net/")
html = response.read()
print(html)
```

# Use `BeautifulSoup` to clean the grabbed text
```python3
from bs4 import BeautifulSoup
soup = BeautifulSoup(html,"html5lib")
text = soup.get_text(strip=True)
print(text)
```

# Use `.split()` to convert text into tokens

```python3
tokens = [t for t in text.split()]
print(tokens)
```

# Use `nltk.FreqDist()` Count word frequency
```python3
freq = nltk.FreqDist(tokens)
for key,val in freq.items():
    print (str(key) + ":" + str(val))
```


# Plot using `freq.plot(20,cumulative=False)`
```python3
freq.plot(20,cumulative=False)
```

# Removing Stop Words Using nltk

## install `stopwords` first
```python3
import nltk
nltk.download('stopwords')
```

## Remove stopwords from `stopwords.words('english')`
```python3
from nltk.corpus import stopwords

clean_tokens = tokens[:]
sr = stopwords.words('english')
for token in tokens:
    if token in sr:
        clean_tokens.remove(token)
freq = nltk.FreqDist(clean_tokens)
for key,val in freq.items():
    print (str(key) + ":" + str(val))
```

# Tokenlize text to sentences

## install `punkt` first

```python3
import nltk
nltk.download('punkt')
```

## use `sent_tokenize()` to parse the text to sentences
```python3
from nltk.tokenize import sent_tokenize
mytext = "Hello Adam, how are you? I hope everything is going well. Today is a good day, see you dude."
print(sent_tokenize(mytext))
```

## use `word_tokenize()` to parse the text to sentences
```python3
from nltk.tokenize import word_tokenize
print(word_tokenize(mytext))
```

# Get synonyms from WordNet

## install `wordnet` first

```python3
import nltk
nltk.download('wordnet')
```

## Use `wordnet.synsets()` as dictionary
```python3
from nltk.corpus import wordnet
syn = wordnet.synsets("pain")
print(syn[0].definition())
print(syn[0].examples())
```


## Use `.lemmas()` to get synonymous/antonyms words
```python3
synonyms = []
for syn in wordnet.synsets("Computer"):
  for lemma in syn.lemmas():
    synonyms.append(lemma.name())
print(synonyms)

antonyms = []
for syn in wordnet.synsets("small"):
  for l in syn.lemmas():
    if l.antonyms():
      antonyms.append(l.antonyms()[0].name())
print(antonyms)
```

# Word stemming via `PorterStemmer()`

```python3
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()
print(stemmer.stem("working"))
```

# Word lemmatizing (meaning real word) via `WordNetLemmatizer()`

```python3
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
print(lemmatizer.lemmatize("increases")) # default nouns
print(lemmatizer.lemmatize("playing",pos="v")) # get verbs
print(lemmatizer.lemmatize("playing",pos="n")) # get nons
print(lemmatizer.lemmatize("playing",pos="a")) # get adj
print(lemmatizer.lemmatize("playing",pos="r")) # get adv
```
